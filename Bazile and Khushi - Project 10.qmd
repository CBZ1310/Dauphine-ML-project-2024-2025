---
title: "Machine Learning - Final project (project 10)"
author: "Bazile Cédric and Jain Khushi"
format: pdf
editor: visual
---

```{r}
#Libraries
here::i_am("Dauphine-ML-project-2024-2025.Rproj")
library(here)
library(readr)

## Data management
library(dplyr)
library(tidyr)
library(data.table)
library(stringr)


## Graphics libraries
library(ggplot2)
library(scales)
library(plotly)

## ML
library(torch)
```

## Introduction

## Cleaning phase

```{r}
#Learning data set

## Import data
learn_df <- read_csv("Data - source/project-10-files/learn_dataset.csv")

##Check for NA
learn_df %>%  summarise_all(~ sum(is.na(.))) # No missing data

# Test dataset
## Import data
test_df <- read_csv("Data - source/project-10-files/learn_dataset.csv")
any(duplicated(learn_df$KEY_PRIMARY)) 

##Check for NA
test_df %>%  summarise_all(~ sum(is.na(.))) # No missing data
any(duplicated(test_df$KEY_PRIMARY)) 
```

The principal datasets, both from the learning and testing phases, do not contain missing values or duplicates. However, as indicated in the instructions, a large number of missing values exist when adding the additional data on retirement, sports, and jobs.

```{r Create_the_dataframe_learning_data}

# Import additional data

learn_emp_type <- read_csv("Data - source/project-10-files/learn_dataset_emp_type.csv")

learn_job <- read_csv("Data - source/project-10-files/learn_dataset_job.csv")

learn_retired_former <- read_csv("Data - source/project-10-files/learn_dataset_retired_former.csv")

learn_retired_jobs <- read_csv("Data - source/project-10-files/learn_dataset_retired_jobs.csv")

learn_retired_pension <- read_csv("Data - source/project-10-files/learn_dataset_retired_pension.csv")

learn_sport <- read_csv("Data - source/project-10-files/learn_dataset_sport.csv")

# Chekcing for duplicate
 
any(duplicated(learn_emp_type$KEY_PRIMARY))
any(duplicated(learn_job$KEY_PRIMARY))
any(duplicated(learn_retired_former$KEY_PRIMARY))
any(duplicated(learn_retired_jobs$KEY_PRIMARY))
any(duplicated(learn_retired_pension$KEY_PRIMARY))
any(duplicated(learn_sport$KEY_PRIMARY))
# No duplicates found

# Merger with left join
learn_merged <- learn_df %>%
  left_join(learn_emp_type, by = "PRIMARY_KEY") %>%
  left_join(learn_job, by = "PRIMARY_KEY") %>%
  left_join(learn_retired_former, by = "PRIMARY_KEY") %>%
  left_join(learn_retired_jobs, by = "PRIMARY_KEY") %>%
  left_join(learn_retired_pension, by = "PRIMARY_KEY") %>%
  left_join(learn_sport, by = "PRIMARY_KEY")


```

```{r Create_the_dataframe_test_data}

# Import additional data

test_emp_type <- read_csv("Data - source/project-10-files/test_dataset_emp_type.csv")

test_job <- read_csv("Data - source/project-10-files/test_dataset_job.csv")

test_retired_former <- read_csv("Data - source/project-10-files/test_dataset_retired_former.csv")

test_retired_jobs <- read_csv("Data - source/project-10-files/test_dataset_retired_jobs.csv")

test_retired_pension <- read_csv("Data - source/project-10-files/test_dataset_retired_pension.csv")

test_sport <- read_csv("Data - source/project-10-files/test_dataset_sport.csv")

# Chekcing for duplicate
 
any(duplicated(test_emp_type$KEY_PRIMARY))
any(duplicated(test_job$KEY_PRIMARY))
any(duplicated(test_retired_former$KEY_PRIMARY))
any(duplicated(test_retired_jobs$KEY_PRIMARY))
any(duplicated(test_retired_pension$KEY_PRIMARY))
any(duplicated(test_sport$KEY_PRIMARY))
# No duplicates found

# Merger with left join
test_merged <- test_df %>%
  left_join(test_emp_type, by = "PRIMARY_KEY") %>%
  left_join(test_job, by = "PRIMARY_KEY") %>%
  left_join(test_retired_former, by = "PRIMARY_KEY") %>%
  left_join(test_retired_jobs, by = "PRIMARY_KEY") %>%
  left_join(test_retired_pension, by = "PRIMARY_KEY") %>%
  left_join(test_sport, by = "PRIMARY_KEY")

```

```{r NA_tables}

# List of the column of the main dataset : this list will be used to keep only columns of the additional dataset in order to see the number and frequency of NA
learn_original_columns <- colnames(learn_df)
test_original_columns <- colnames(test_df)

# Learning set : Number of NA for each column
learn_na_count <- learn_merged %>%
  select(-all_of(learn_original_columns)) %>%  
  summarise(across(everything(), ~ as.integer(sum(is.na(.))))) %>%
  mutate(Statistics = "Learning set : count")  # Addition of a column to name the created statistics

# Learning set : % of NA for each colummn
learn_na_percentage <- learn_merged %>%
  select(-all_of(learn_original_columns)) %>%  
  summarise(across(everything(), ~ as.integer(mean(is.na(.))*100))) %>%
  mutate(Statistics = "Learning set : percentage")  

# Test set : Number of NA for each column
test_na_count <- test_merged %>%
  select(-all_of(test_original_columns)) %>%  
  summarise(across(everything(), ~ as.integer(sum(is.na(.))))) %>%
  mutate(Statistics = "Test set : count")  # Addition of a column to indicate the stat

# Test set : % of NA for each colummn
test_na_percentage <- test_merged %>%
  select(-all_of(test_original_columns)) %>%  
  summarise(across(everything(), ~ as.integer(mean(is.na(.))*100))) %>%
  mutate(Statistics = "Test set : percentage") 

# Creation of the final table
na_sum_table <- bind_rows(learn_na_count, learn_na_percentage, test_na_count, test_na_percentage) %>% 
  relocate(Statistics, .before = everything())

print(na_sum_table)
```

In addition to the learning and test dataset, we also used to additional dataset

-   the variable "community_size" of "city_pop", even if the target variable is not describe demographic size of a town has strong correlation with market size, job and available infrastructure;

-   the variable "town_type" of the dataset "city_adm" : our hypothesis key cities like state capital or "préfecture" can benefit from greater investment and infrastucture or at the opposite it is because of their historical attractivity that they add be chosen as "préfecture";

-   and, the variable "dep" of the dataset "city_adm" in order to take into account potential departemental variation.

No missing values were found to report..

```{r Addition_of_demographic_data}
# Importation of the  dataset

city_adm <- read_csv("Data - source/project-10-files/city_adm.csv", 
                     col_types = cols(INSEE = col_character())) # the option col_types makes sure that INSEE's code are treated as characters what was not automatically the case this time during importation. 

city_pop <- read_csv("Data - source/project-10-files/city_pop.csv", 
    col_types = cols(INSEE = col_character()))


# Merging
learn_merged <- learn_merged %>% 
  left_join(city_adm, by = "INSEE") %>% 
  left_join(city_pop, by = "INSEE")

test_merged <- test_merged %>% 
  left_join(city_adm, by = "INSEE") %>% 
  left_join(city_pop, by = "INSEE")

# Checking NA for new data
col_demo_data <- colnames(left_join(city_adm, city_pop, by = "INSEE")) #column names of the new data

demo_learn_na_count <- learn_merged %>%
  select(col_demo_data) %>%  
  summarise(across(everything(), ~ as.integer(sum(is.na(.))))) %>%
  mutate(Statistics = "Learning set : count")


demo_test_na_count <- test_merged %>%
  select(col_demo_data) %>%  
  summarise(across(everything(), ~ as.integer(sum(is.na(.))))) %>%
  mutate(Statistics = "Test set : count")


demo_na_sum_table <- bind_rows(demo_learn_na_count, demo_test_na_count) 

# Removing intermediary columns
rm(col_demo_data)
rm(demo_test_na_count)
rm(demo_learn_na_count)
```

```{r uncoded_version_of_the_data}
# Liste tous les fichiers CSV dans le dossier
data_description <- "Data - source/project-10-files/code"

## Opening all the csv starting with "code"
fichiers_csv <- list.files(data_description, pattern = "*.csv", full.names = TRUE)

for (fichier in fichiers_csv) {
  nom_dataframe <- tools::file_path_sans_ext(basename(fichier))  # Utilise le nom du fichier sans extension
  assign(nom_dataframe, read.csv(fichier))  # Crée une variable avec ce nom et charge le CSV
}
 
```

## Descriptive Statistics
