---
title: "Machine Learning - Final project (project 10)"
author: "Bazile Cédric and Jain Khushi"
format: pdf
editor: visual
---

```{r}
#Libraries
here::i_am("Dauphine-ML-project-2024-2025.Rproj")
library(here)
library(readr)

## Data management
library(dplyr)
library(tidyr)
library(data.table)
library(stringr)
library(knitr)
library(recipes)
library(missForest)



## Graphics libraries
library(ggplot2)
library(scales)
library(plotly)
library(DataExplorer)
library(viridis)

## ML
library(parsnip)
library(tune)
library(yardstick)
library(randomForest)
library(ranger)
```

## Introduction

## Cleaning phase

```{r}
#Learning data set

## Import data
learn_df <- read_csv("Data - source/project-10-files/learn_dataset.csv")

##Check for NA
learn_df %>%  summarise_all(~ sum(is.na(.))) # No missing data

# Test dataset
## Import data
test_df <- read_csv("Data - source/project-10-files/test_dataset.csv")
any(duplicated(learn_df$PRIMARY_KEY)) 

##Check for NA
test_df %>%  summarise_all(~ sum(is.na(.))) # No missing data
any(duplicated(test_df$PRIMARY_KEY)) 
```

The principal datasets, both from the learning and testing phases, do not contain missing values or duplicates. However, as indicated in the instructions, a large number of missing values exist when adding the additional data on retirement, sports, and jobs.

```{r Create_the_dataframe_learning_data_part_one}

# Import additional data

learn_emp_type <- read_csv("Data - source/project-10-files/learn_dataset_emp_type.csv")

learn_job <- read_csv("Data - source/project-10-files/learn_dataset_job.csv")

learn_retired_former <- read_csv("Data - source/project-10-files/learn_dataset_retired_former.csv")

learn_retired_jobs <- read_csv("Data - source/project-10-files/learn_dataset_retired_jobs.csv")

learn_retired_pension <- read_csv("Data - source/project-10-files/learn_dataset_retired_pension.csv")

learn_sport <- read_csv("Data - source/project-10-files/learn_dataset_sport.csv")

# Chekcing for duplicate
 
any(duplicated(learn_emp_type$KEY_PRIMARY))
any(duplicated(learn_job$KEY_PRIMARY))
any(duplicated(learn_retired_former$KEY_PRIMARY))
any(duplicated(learn_retired_jobs$KEY_PRIMARY))
any(duplicated(learn_retired_pension$KEY_PRIMARY))
any(duplicated(learn_sport$KEY_PRIMARY))
# No duplicates found




```

```{r Create_the_dataframe_learning_data_part_two}
# Merger with left join
learn_merged <- learn_df %>%
  left_join(learn_emp_type, by = "PRIMARY_KEY") %>%
  left_join(learn_job, by = "PRIMARY_KEY") %>%
  left_join(learn_retired_former, by = "PRIMARY_KEY") %>%
  left_join(learn_retired_jobs, by = "PRIMARY_KEY") %>%
  left_join(learn_retired_pension, by = "PRIMARY_KEY") %>%
  left_join(learn_sport, by = "PRIMARY_KEY") %>% 

   mutate(TYPE_CONTRACT = ifelse(is.na(TYPE_OF_CONTRACT.x), TYPE_OF_CONTRACT.y, TYPE_OF_CONTRACT.x),
         Working_hours = ifelse(is.na(Working_hours.x), Working_hours.y, Working_hours.x),
         Work_condition = ifelse(is.na(Work_condition.x), Work_condition.y, Work_condition.x),
         company_category = ifelse(is.na(company_category.x), company_category.y, company_category.x),
         ECO_SECT = ifelse(is.na(ECO_SECT.x), ECO_SECT.y, ECO_SECT.x),
         job_desc = ifelse(is.na(job_desc.x), job_desc.y, job_desc.x),
         employee_count = ifelse(is.na(employee_count.x), employee_count.y, employee_count.x),
         Job_dep = ifelse(is.na(Job_dep.x), Job_dep.y, Job_dep.x),
         job_category = ifelse(is.na(job_category.x), job_category.y, job_category.x)) %>%
  
  select(-ends_with(".x"), -ends_with(".y"))
```

```{r Create_the_dataframe_test_data_part_one}

# Import additional data

test_emp_type <- read_csv("Data - source/project-10-files/test_dataset_emp_type.csv")

test_job <- read_csv("Data - source/project-10-files/test_dataset_job.csv")

test_retired_former <- read_csv("Data - source/project-10-files/test_dataset_retired_former.csv")

test_retired_jobs <- read_csv("Data - source/project-10-files/test_dataset_retired_jobs.csv")

test_retired_pension <- read_csv("Data - source/project-10-files/test_dataset_retired_pension.csv")

test_sport <- read_csv("Data - source/project-10-files/test_dataset_sport.csv")

# Chekcing for duplicate
 
any(duplicated(test_emp_type$KEY_PRIMARY))
any(duplicated(test_job$KEY_PRIMARY))
any(duplicated(test_retired_former$KEY_PRIMARY))
any(duplicated(test_retired_jobs$KEY_PRIMARY))
any(duplicated(test_retired_pension$KEY_PRIMARY))
any(duplicated(test_sport$KEY_PRIMARY))
# No duplicates found

```

```{r Create_the_dataframe_test_data_part_two}

# Merger with left join
test_merged <- test_df %>%
  left_join(test_emp_type, by = "PRIMARY_KEY") %>%
  left_join(test_job, by = "PRIMARY_KEY") %>%
  left_join(test_retired_former, by = "PRIMARY_KEY") %>%
  left_join(test_retired_jobs, by = "PRIMARY_KEY") %>%
  left_join(test_retired_pension, by = "PRIMARY_KEY") %>%
  left_join(test_sport, by = "PRIMARY_KEY")

```

```{r NA_tables}

# List of the column of the main dataset : this list will be used to keep only columns of the additional dataset in order to see the number and frequency of NA
learn_original_columns <- colnames(learn_df)
test_original_columns <- colnames(test_df)

# Learning set : Number of NA for each column
learn_na_count <- learn_merged %>%
  select(-all_of(learn_original_columns)) %>%  
  summarise(across(everything(), ~ as.integer(sum(is.na(.))))) %>%
  mutate(Statistics = "Learning set : count")  # Addition of a column to name the created statistics

# Learning set : % of NA for each colummn
learn_na_percentage <- learn_merged %>%
  select(-all_of(learn_original_columns)) %>%  
  summarise(across(everything(), ~ as.integer(mean(is.na(.))*100))) %>%
  mutate(Statistics = "Learning set : percentage")  

# Test set : Number of NA for each column
test_na_count <- test_merged %>%
  select(-all_of(test_original_columns)) %>%  
  summarise(across(everything(), ~ as.integer(sum(is.na(.))))) %>%
  mutate(Statistics = "Test set : count")  # Addition of a column to indicate the stat

# Test set : % of NA for each colummn
test_na_percentage <- test_merged %>%
  select(-all_of(test_original_columns)) %>%  
  summarise(across(everything(), ~ as.integer(mean(is.na(.))*100))) %>%
  mutate(Statistics = "Test set : percentage") 

# Creation of the final table
na_sum_table <- bind_rows(learn_na_count, learn_na_percentage, test_na_count, test_na_percentage) %>% 
  relocate(Statistics, .before = everything())

print(na_sum_table)
```

In addition to the learning and test dataset, we also used to additional dataset :

-   the variable "community_size" of "city_pop" : our hypothezis is even if the target variable is not described demographic size of a town has strong correlation with market size, job and available infrastructure and thus information that can probably impact this targert variable;

-   the variable "town_type" of the dataset "city_adm" : our hypothesis is that key cities like state capital or "préfecture" can benefit from greater investment and infrastucture. Similarly, because of their historical attractivity that they add be chosen as "préfecture";

-   and, the variable "dep" of the dataset "city_adm" in order to take into account potential departemental variation.

No missing values were found to report.

```{r Addition_of_demographic_data}
# Importation of the  dataset

city_adm <- read_csv("Data - source/project-10-files/city_adm.csv", 
                     col_types = cols(INSEE = col_character())) # the option col_types makes sure that INSEE's code are treated as characters what was not automatically the case this time during importation. 

city_pop <- read_csv("Data - source/project-10-files/city_pop.csv", 
    col_types = cols(INSEE = col_character()))


# Merging
learn_merged <- learn_merged %>% 
  left_join(city_adm, by = "INSEE") %>% 
  left_join(city_pop, by = "INSEE")

test_merged <- test_merged %>% 
  left_join(city_adm, by = "INSEE") %>% 
  left_join(city_pop, by = "INSEE")

# Checking NA for new data
col_demo_data <- colnames(left_join(city_adm, city_pop, by = "INSEE")) #column names of the new data

demo_learn_na_count <- learn_merged %>%
  select(col_demo_data) %>%  
  summarise(across(everything(), ~ as.integer(sum(is.na(.))))) %>%
  mutate(Statistics = "Learning set : count")


demo_test_na_count <- test_merged %>%
  select(col_demo_data) %>%  
  summarise(across(everything(), ~ as.integer(sum(is.na(.))))) %>%
  mutate(Statistics = "Test set : count")


demo_na_sum_table <- bind_rows(demo_learn_na_count, demo_test_na_count) 

# Removing intermediary columns
rm(col_demo_data)
rm(demo_test_na_count)
rm(demo_learn_na_count)
```

We started by looking at an overview of the dataset content. It allow us to see whether some variables were mischaracterized.

```{r}
# Creation of table with the type, number of variable and their name
variable_summary <- learn_merged %>%
  summarise(across(everything(), ~ class(.)[1])) %>%  
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Type") %>% 
  group_by(Type) %>% 
  summarise(
    `Number of Variables` = n(),
    `List of Variables` = paste(Variable, collapse = ", "))

variable_summary %>%
  kable(
    caption = "Summary of Variable Types in Dataset",
    align = "l")

```

The table below list the different string variable and the number of unique value each of them has.

```{r}
# Identifying column considered as string
string_columns_summary <- learn_merged %>%
  select(where(is.character)) %>%
  summarise(across(everything(), ~ n_distinct(.))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Unique Values")

# Afficher le tableau avec un titre
string_columns_summary %>%
  kable(
    col.names = c("Variable", "Unique values"),
    caption = "Summary of String Variables and Their Unique Values",
    align = "l"
  )
```

We decided at this step of our work to transform the string values into factor.

```{r}
learn_merged <- learn_merged %>%
  mutate(across(where(is.character), as.factor))

test_merged <- test_merged %>%
  mutate(across(where(is.character), as.factor))

#checking final result
variable_summary_after_transformation_learn <- learn_merged %>%
  summarise(across(everything(), ~ class(.)[1])) %>%  
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Type") %>% 
  group_by(Type) %>% 
  summarise(
    `Number of Variables` = n(),
    `List of Variables` = paste(Variable, collapse = ", "))

variable_summary_after_transformation_test <- test_merged %>%
  summarise(across(everything(), ~ class(.)[1])) %>%  
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Type") %>% 
  group_by(Type) %>% 
  summarise(
    `Number of Variables` = n(),
    `List of Variables` = paste(Variable, collapse = ", "))

rm(variable_summary_after_transformation_learn)
rm(variable_summary_after_transformation_test)
rm(variable_summary)
```

## Exploring the dataset

### Distribution of the target variable

The target variable as a higher proportion of value equal to A than value equal to E in the learning set. The graphic below give us the number of rows by category of the variable "target".

```{r}

#Graphics 

## Count (N)
ggplot(learn_merged, aes(x = target, fill = target)) +
  geom_bar(width = 0.6) + # Réduction de la largeur des bins
  geom_text(stat = "count", aes(label = after_stat(count)), vjust = -0.5) + # Ajout des étiquettes avec `after_stat`
  labs(title = "Distribution of the Target Variable", x = "Target", y = "Count", fill = "Target") +
  scale_fill_viridis_d(option = "turbo") +
  theme_minimal()




#Statistics for the text below
## Values on N and percentage
n_A <- learn_merged %>% filter(target == "A") %>% nrow()
percent_A <- (n_A / nrow(learn_merged)) * 100

n_E <- learn_merged %>% filter(target == "E") %>% nrow()
percent_E <- (n_E / nrow(learn_merged)) * 100

# Calculate the ratio between A and E
ratio_A_E <- round(n_A / n_E, 1)
```

The target variable has a higher proportion of value "A" compared to "E" in the dataset. **`r n_A`** individual has A for tager which represents **`r round(percent_A, 2)`%** of the total rows. Paralelly, **`r round(percent_E, 2)`%** of the individuals has E for target (**`r n_E`** rows).

```{r}
## Percent (%)
data_percent <- learn_merged %>%
  count(target) %>%
  mutate(percentage = (n / sum(n)) * 100)

ggplot(data_percent, aes(x = 1, y = percentage, fill = target)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(round(percentage, 1), "%")), 
            position = position_stack(vjust = 0.5), color = "white", size = 4) +
  labs(
    title = "Percentage Distribution of Target Categories",
    fill = "Target"  ) +
  scale_fill_viridis_d(option = "turbo") +
  theme_minimal() +
  coord_flip()
```

In other words, there are **`r ratio_A_E`** times more A than E in the dataset.

### Understanding the NA

```{r Addition_of_the_translation_of_the_code, results = "hide"}
################################     Town type       ###############################

#Translation
learn_merged_uncoded <- learn_merged %>%
  mutate(town_type_translated = case_when(
    grepl("Commune simple", town_type) ~ "Simple municipality",
    grepl("Chef-lieu canton", town_type) ~ "Canton capital",
    grepl("Préfecture de région", town_type) ~ "Regional prefecture",
    grepl("Préfecture", town_type) ~ "Prefecture",
    grepl("Sous-préfecture", town_type) ~ "Sub-prefecture",
    grepl("Capitale d'état", town_type) ~ "State capital",
    TRUE ~ town_type  # Conserve la valeur d'origine si non traduite
  ))

# Display the comparison of unique French values with their translations to check if there are any mistakes
comparison_table <- learn_merged_uncoded %>%
  select(town_type, town_type_translated) %>%
  distinct()

################################     Code Act       ################################
#Import
code_act <- read_csv("Data - source/project-10-files/code/code_act.csv")

#Merging
learn_merged_uncoded <- merge(learn_merged_uncoded, code_act, by.x = "act", by.y = "Code", all.x = TRUE, all.y = FALSE)
sum(is.na(learn_merged_uncoded$Libellé)) #no missing values

# Translation of the "Libellé"
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(act_translated = case_when(
    grepl("Actifs", Libellé) ~ "Active workers, including apprenticeships or paid internships.",
    grepl("Chômeurs", Libellé) ~ "Unemployed",
    grepl("Retraités|prérétaités", Libellé) ~ "Retirees or early retirees",
    grepl("Élèves|étudiants|stagiaires", Libellé) ~ "Students, unpaid trainees aged 14 or older",
    grepl("Moins de 14 ans", Libellé) ~ "Under 14 years old",
    grepl("Femmes|hommes au foyer", Libellé) ~ "Homemakers",
    grepl("Autres inactifs", Libellé) ~ "Other inactive people",
    TRUE ~ Libellé  # Default: keep original if no match
  ))



# Display the comparison of unique French values with their translations to check if there is any mistakes
comparison_table <- learn_merged_uncoded %>%
  select(Libellé, act_translated) %>%
  distinct()

# Suprresion of unuseful data
learn_merged_uncoded <- learn_merged_uncoded %>%
  select(-Libellé)
rm(code_act)

################################ Code Household type ###############################
# Import
code_Household_type <- read_csv("Data - source/project-10-files/code/code_Household_type.csv")

#Merging
learn_merged_uncoded <- merge(learn_merged_uncoded, code_Household_type, by.x = "Household_type", by.y = "Code", all.x = TRUE, all.y = FALSE)
sum(is.na(learn_merged_uncoded$Libellé)) #no missing values

# Translation
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(Household_type_translated = case_when(
    grepl("Homme vivant seul", Libellé) ~ "Man living alone",
    grepl("Femme vivant seule", Libellé) ~ "Woman living alone",
    grepl("Plusieurs personnes sans famille", Libellé) ~ "Multiple people without family",
    grepl("Famille principale monoparentale composée d'un homme", Libellé) ~ "Single-parent family led by a man",
    grepl("Famille principale monoparentale composée d'une femme", Libellé) ~ "Single-parent family led by a woman",
    grepl("Famille principale composée d'un couple de deux 'actifs", Libellé) ~ "Main family composed of a couple of two active workers",
    grepl("Famille principale composée d'un couple où seul un homme", Libellé) ~ "Main family composed of a couple where only the man is active",
    grepl("Famille principale composée d'un couple où seule une femme", Libellé) ~ "Main family composed of a couple where only the woman is active",
    grepl("Famille principale composée d'un couple d'aucun 'actif", Libellé) ~ "Main family composed of a couple with no active workers",
    TRUE ~ Libellé  # Default: keep original if no match
  ))

comparison_table <- learn_merged_uncoded %>%
  select(Libellé, Household_type_translated) %>%
  distinct()

# Suprresion of unuseful data
learn_merged_uncoded <- learn_merged_uncoded %>%
  select(-Libellé)
rm(code_Household_type)

################################ Code Highest Degree ###############################
# Import
code_Highest_degree <- read_csv("Data - source/project-10-files/code/code_Highest_degree.csv")

# Merging
learn_merged_uncoded <- merge(learn_merged_uncoded, code_Highest_degree, by.x = "Highest_degree", by.y = "Code", all.x = TRUE, all.y = FALSE)
sum(is.na(learn_merged_uncoded$Libellé)) # Check for missing values

# Translation of "Highest_degree"
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(Highest_degree_translated = case_when(
    grepl("Pas de scolarité ou arrêt avant la fin du primaire", Libellé) ~ "No schooling or dropout at the end of primary school",
    grepl("CEP", Libellé) ~ "Primary school certificate",
    grepl("BEPC, brevet élémentaire, brevet des collèges", Libellé) ~ "Middle school diploma or equivalent",
    grepl("CAP, BEP ou diplôme de niveau équivalent", Libellé) ~ "Vocational diploma (CAP/BEP or equivalent)",
    grepl("Baccalauréat général ou technologique", Libellé) ~ "General or technological high school diploma",
    grepl("Baccalauréat professionnel", Libellé) ~ "Professional high school diploma",
    grepl("BTS, DUT, Deug", Libellé) ~ "University technical diploma or associate degree",
    grepl("Licence|licence pro|maîtrise", Libellé) ~ "Bachelor's degree or equivalent",
    grepl("Master|DEA|DESS", Libellé) ~ "Master's degree or equivalent",
    grepl("Doctorat", Libellé) ~ "Doctorate or equivalent",
     grepl("Aucun diplôme et scolarité interrompue à la fin du primaire", Libellé) ~ "No degree, interrupted schooling at the end of primary school or before the end of middle-school",
    grepl("au-delà", Libellé) ~ "No degree, completed schooling up to middle school or beyond",
    TRUE ~ Libellé  # Default: keep the original if no match
  ))


# Display the comparison of unique French values with their translations to check if there are any mistakes
comparison_table <- learn_merged_uncoded %>%
  select(Libellé, Highest_degree_translated) %>%
  distinct()

# Suppression of unuseful data
learn_merged_uncoded <- learn_merged_uncoded %>%
  select(-Libellé)
rm(code_Highest_degree)

################################ Code JOB 42 ###############################
# Import
code_JOB_42 <- read_csv("Data - source/project-10-files/code/code_JOB_42.csv")

# Merging
learn_merged_uncoded <- merge(learn_merged_uncoded, code_JOB_42, by.x = "JOB_42", by.y = "Code", all.x = TRUE, all.y = FALSE)
sum(is.na(learn_merged_uncoded$Libellé)) # Check for missing values

# Translation
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(JOB_42_translated = case_when(
    grepl("Agriculteurs sur petite exploitation", Libellé) ~ "Small-scale farmers",
    grepl("Agriculteurs sur moyenne exploitation", Libellé) ~ "Medium-scale farmers",
    grepl("Agriculteurs sur grande exploitation", Libellé) ~ "Large-scale farmers",
    grepl("Artisans", Libellé) ~ "Craftsmen",
    grepl("Commerçants et assimilés", Libellé) ~ "Merchants and related trades",
    grepl("Chefs d'entreprise de 10 salariés ou plus", Libellé) ~ "Business owners with 10 or more employees",
    grepl("Professions libérales", Libellé) ~ "Freelancers or independent professionals",
    grepl("Cadres de la fonction publique", Libellé) ~ "Public sector executives",
    grepl("Professeurs, professions scientifiques", Libellé) ~ "Teachers and scientific professionals",
    grepl("Professions de l'information, des arts et des spectacles", Libellé) ~ "Information, arts, and entertainment professionals",
    grepl("Clergé, religieux", Libellé) ~ "Clergy and religious professionals",
    grepl("Cadres administratifs et commerciaux d'entreprise", Libellé) ~ "Corporate administrative and commercial executives",
    grepl("Ingénieurs et cadres techniques d'entreprise", Libellé) ~ "Engineers and technical managers",
    grepl("Techniciens", Libellé) ~ "Technicians",
    grepl("Contremaîtres, agents de maîtrise", Libellé) ~ "Foremen and supervisors",
    grepl("Employés civils et agents de service de la fonction publique", Libellé) ~ "Public sector employees and service agents",
    grepl("Policiers et militaires", Libellé) ~ "Police and military personnel",
    grepl("Employés administratifs d'entreprise", Libellé) ~ "Corporate administrative employees",
    grepl("Employés de commerce", Libellé) ~ "Retail employees",
    grepl("Personnels des services directs aux particuliers", Libellé) ~ "Personal service workers",
    grepl("Ouvriers qualifiés de type industriel", Libellé) ~ "Skilled industrial workers",
    grepl("Ouvriers qualifiés de type artisanal", Libellé) ~ "Skilled artisanal workers",
    grepl("Ouvriers qualifiés de la manutention, du magasinage et du transport", Libellé) ~ "Skilled manual and transport workers",
    grepl("Ouvriers non qualifiés de type industriel", Libellé) ~ "Unskilled industrial workers",
    grepl("Ouvriers non qualifiés de type artisanal", Libellé) ~ "Unskilled artisanal workers",
    grepl("Ouvriers agricoles", Libellé) ~ "Agricultural workers",
    grepl("Chauffeurs", Libellé) ~ "Drivers",
    grepl("Anciens agriculteurs exploitants", Libellé) ~ "Retired farmers",
    grepl("Anciens artisans, commerçants, chefs d'entreprise", Libellé) ~ "Retired craftsmen, merchants, and business owners",
    grepl("Anciens cadres", Libellé) ~ "Retired executives",
    grepl("Anciens employés", Libellé) ~ "Retired employees",
    grepl("Anciens ouvriers", Libellé) ~ "Retired workers",
    grepl("Chômeurs n'ayant jamais travaillé", Libellé) ~ "Unemployed who have never worked",
    grepl("tudiant", Libellé) ~ "Students",
    grepl("de moins de 60 ans", Libellé) ~ "People without professional activity under 60 (excluded Retired ppl)",
    grepl("Personnes diverses sans activité professionnelle de 60 ans et plus", Libellé) ~ "People without professional activity 60 and older (excluded Retired ppl)",
    grepl("Professeurs des écoles, instituteurs et assimilés", Libellé) ~ "Primary school teachers, instructors, and related professions",
  grepl("Professions intermédiaires de la santé et du travail social", Libellé) ~ "Intermediate health and social work professions",
  grepl("Clergé religieux", Libellé) ~ "Clergy and religious professionals",
  grepl("Professions intermédiaires administratives de la fonction publique", Libellé) ~ "Intermediate administrative professions in public administration",
  grepl("Professions intermédiaires administratives et commerciales des entreprises", Libellé) ~ "Intermediate administrative and commercial professions in companies",
  grepl("Anciennes professions intermédiaires", Libellé) ~ "Former intermediate professions",
  grepl("du travail social", Libellé) ~ "Intermediate health and social work professionals",
    TRUE ~ Libellé  # Default: keep original if no match
  ))



# Display the comparison of unique French values with their translations to check if there are any mistakes
comparison_table <- learn_merged_uncoded %>%
  select(Libellé, JOB_42_translated) %>%
  distinct()

# Suppression of unuseful data
learn_merged_uncoded <- learn_merged_uncoded %>%
  select(-Libellé)
rm(code_JOB_42)

```

```{r Addition_of_the_translation_of_the_code_part_two, results = "hide"}

################################ Code LAST JOB 42 ###############################
# Import
code_JOB_42 <- read_csv("Data - source/project-10-files/code/code_JOB_42.csv")

# Merging
learn_merged_uncoded <- merge(learn_merged_uncoded, code_JOB_42, by.x = "LAST_JOB_42", by.y = "Code", all.x = TRUE, all.y = FALSE)
sum(is.na(learn_merged_uncoded$Libellé)) # Check for missing values

# Translation
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(LAST_JOB_42_translated = case_when(
    grepl("Agriculteurs sur petite exploitation", Libellé) ~ "Small-scale farmers",
    grepl("Agriculteurs sur moyenne exploitation", Libellé) ~ "Medium-scale farmers",
    grepl("Agriculteurs sur grande exploitation", Libellé) ~ "Large-scale farmers",
    grepl("Artisans", Libellé) ~ "Craftsmen",
    grepl("Commerçants et assimilés", Libellé) ~ "Merchants and related trades",
    grepl("Chefs d'entreprise de 10 salariés ou plus", Libellé) ~ "Business owners with 10 or more employees",
    grepl("Professions libérales", Libellé) ~ "Freelancers or independent professionals",
    grepl("Cadres de la fonction publique", Libellé) ~ "Public sector executives",
    grepl("Professeurs, professions scientifiques", Libellé) ~ "Teachers and scientific professionals",
    grepl("Professions de l'information, des arts et des spectacles", Libellé) ~ "Information, arts, and entertainment professionals",
    grepl("Clergé, religieux", Libellé) ~ "Clergy and religious professionals",
    grepl("Cadres administratifs et commerciaux d'entreprise", Libellé) ~ "Corporate administrative and commercial executives",
    grepl("Ingénieurs et cadres techniques d'entreprise", Libellé) ~ "Engineers and technical managers",
    grepl("Techniciens", Libellé) ~ "Technicians",
    grepl("Contremaîtres, agents de maîtrise", Libellé) ~ "Foremen and supervisors",
    grepl("Employés civils et agents de service de la fonction publique", Libellé) ~ "Public sector employees and service agents",
    grepl("Policiers et militaires", Libellé) ~ "Police and military personnel",
    grepl("Employés administratifs d'entreprise", Libellé) ~ "Corporate administrative employees",
    grepl("Employés de commerce", Libellé) ~ "Retail employees",
    grepl("Personnels des services directs aux particuliers", Libellé) ~ "Personal service workers",
    grepl("Ouvriers qualifiés de type industriel", Libellé) ~ "Skilled industrial workers",
    grepl("Ouvriers qualifiés de type artisanal", Libellé) ~ "Skilled artisanal workers",
    grepl("Ouvriers qualifiés de la manutention, du magasinage et du transport", Libellé) ~ "Skilled manual and transport workers",
    grepl("Ouvriers non qualifiés de type industriel", Libellé) ~ "Unskilled industrial workers",
    grepl("Ouvriers non qualifiés de type artisanal", Libellé) ~ "Unskilled artisanal workers",
    grepl("Ouvriers agricoles", Libellé) ~ "Agricultural workers",
    grepl("Chauffeurs", Libellé) ~ "Drivers",
    grepl("Anciens agriculteurs exploitants", Libellé) ~ "Retired farmers",
    grepl("Anciens artisans, commerçants, chefs d'entreprise", Libellé) ~ "Retired craftsmen, merchants, and business owners",
    grepl("Anciens cadres", Libellé) ~ "Retired executives",
    grepl("Anciens employés", Libellé) ~ "Retired employees",
    grepl("Anciens ouvriers", Libellé) ~ "Retired workers",
    grepl("Chômeurs n'ayant jamais travaillé", Libellé) ~ "Unemployed who have never worked",
    grepl("tudiant", Libellé) ~ "Students",
    grepl("de moins de 60 ans", Libellé) ~ "People without professional activity under 60 (excluded Retired ppl)",
    grepl("Personnes diverses sans activité professionnelle de 60 ans et plus", Libellé) ~ "People without professional activity 60 and older (excluded Retired ppl)",
    grepl("Professeurs des écoles, instituteurs et assimilés", Libellé) ~ "Primary school teachers, instructors, and related professions",
  grepl("Professions intermédiaires de la santé et du travail social", Libellé) ~ "Intermediate health and social work professions",
  grepl("Clergé religieux", Libellé) ~ "Clergy and religious professionals",
  grepl("Professions intermédiaires administratives de la fonction publique", Libellé) ~ "Intermediate administrative professions in public administration",
  grepl("Professions intermédiaires administratives et commerciales des entreprises", Libellé) ~ "Intermediate administrative and commercial professions in companies",
  grepl("Anciennes professions intermédiaires", Libellé) ~ "Former intermediate professions",
  grepl("du travail social", Libellé) ~ "Intermediate health and social work professionals",
    TRUE ~ Libellé  # Default: keep original if no match
  ))



# Display the comparison of unique French values with their translations to check if there are any mistakes
comparison_table <- learn_merged_uncoded %>%
  select(Libellé, LAST_JOB_42_translated) %>%
  distinct()

# Suppression of unuseful data
learn_merged_uncoded <- learn_merged_uncoded %>%
  select(-Libellé)
rm(code_JOB_42)


################################ Code Emp type ###############################
# Import code
code_emp_type <- read_csv("Data - source/project-10-files/code/code_emp_type.csv")

# Merging
learn_merged_uncoded <- merge(learn_merged_uncoded, code_emp_type, by.x = "emp_type", by.y = "Code", all.x = TRUE, all.y = FALSE)
sum(is.na(learn_merged_uncoded$Libellé))  # Vérification des valeurs manquantes

# Traduction des libellés
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(emp_type_translated = case_when(
    grepl("apprentissage", Libellé) ~ "Apprenticeship or professionalization contract",
    grepl("agence d'intérim", Libellé) ~ "Temporary placement through an agency",
    grepl("Emplois aidés", Libellé) ~ "Subsidized jobs (insertion contracts, etc.)",
    grepl("Stagiaires rémunérés", Libellé) ~ "Paid trainees in companies",
    grepl("CDD", Libellé) ~ "Other fixed-term jobs, fixed-term contracts, short-term contracts, seasonal contracts, temporary contracts, etc.",
    grepl("CDI", Libellé) ~ "Permanent contract (CDI)",
    grepl("Non salariés : Indépendants", Libellé, ignore.case = TRUE) ~ "Self-employed: Independents",
    grepl("Non salariés : Employeurs", Libellé, ignore.case = TRUE) ~ "Self-employed: Employers",
    grepl("Non salariés : Aides familiaux", Libellé, ignore.case = TRUE) ~ "Self-employed: Family helpers",
    TRUE ~ Libellé))


# Affichage du tableau comparatif des valeurs uniques pour vérifier les traductions
comparison_table <- learn_merged_uncoded %>%
  select(Libellé, emp_type_translated) %>%
  distinct()

# Suppression des colonnes inutiles
learn_merged_uncoded <- learn_merged_uncoded %>%
  select(-Libellé)

# Optionnel : suppression du dataset si plus nécessaire
rm(code_emp_type)

################################ Code Emp type ###############################
# Import code
code_emp_type <- read_csv("Data - source/project-10-files/code/code_emp_type.csv")

# Merging
learn_merged_uncoded <- merge(learn_merged_uncoded, code_emp_type, by.x = "last_emp_type", by.y = "Code", all.x = TRUE, all.y = FALSE)
sum(is.na(learn_merged_uncoded$Libellé))  # Vérification des valeurs manquantes

# Traduction des libellés
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(last_emp_type_translated = case_when(
    grepl("apprentissage", Libellé) ~ "Apprenticeship or professionalization contract",
    grepl("agence d'intérim", Libellé) ~ "Temporary placement through an agency",
    grepl("Emplois aidés", Libellé) ~ "Subsidized jobs (insertion contracts, etc.)",
    grepl("Stagiaires rémunérés", Libellé) ~ "Paid trainees in companies",
    grepl("CDD", Libellé) ~ "Other fixed-term jobs, fixed-term contracts, short-term contracts, seasonal contracts, temporary contracts, etc.",
    grepl("CDI", Libellé) ~ "Permanent contract (CDI)",
    grepl("Non salariés : Indépendants", Libellé, ignore.case = TRUE) ~ "Self-employed: Independents",
    grepl("Non salariés : Employeurs", Libellé, ignore.case = TRUE) ~ "Self-employed: Employers",
    grepl("Non salariés : Aides familiaux", Libellé, ignore.case = TRUE) ~ "Self-employed: Family helpers",
    TRUE ~ Libellé))


# Affichage du tableau comparatif des valeurs uniques pour vérifier les traductions
comparison_table <- learn_merged_uncoded %>%
  select(Libellé, last_emp_type_translated) %>%
  distinct()

# Suppression des colonnes inutiles
learn_merged_uncoded <- learn_merged_uncoded %>%
  select(-Libellé)

# Optionnel : suppression du dataset si plus nécessaire
rm(code_emp_type)

################################ Code Company category ###############################
# Importation
code_company_category <- read_csv("Data - source/project-10-files/code/code_company_category.csv")

# Merging
learn_merged_uncoded <- merge(learn_merged_uncoded, code_company_category, by.x = "company_category", by.y = "Code", all.x = TRUE, all.y = FALSE)
sum(is.na(learn_merged_uncoded$Libellé))  # Vérification des valeurs manquantes

# Translation
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(company_category_translated = case_when(
    grepl("Fonction publique d'état", Libellé) ~ "State public service",
    grepl("Fonction publique territoriale", Libellé) ~ "Territorial public service",
    grepl("Fonction publique hospitalière", Libellé) ~ "Public hospital service",
    grepl("Autres organismes publics administratifs", Libellé) ~ "Other public administrative organizations",
    grepl("Personnes morales de droit public", Libellé) ~ "Legal entities under public law subject to commercial law",
    grepl("Entreprises individuelles", Libellé) ~ "Individual enterprises",
    grepl("Données marquées comme issues de pe particuliers employeurs", Libellé) ~ "Data flagged as private individual employers",
    grepl("Organismes privés spécialisés et groupements de droit privé", Libellé) ~ "Private organizations and groups",
    grepl("Autres sociétés privées", Libellé) ~ "Other private companies",
    TRUE ~ Libellé))

# Checking
comparison_table <- learn_merged_uncoded %>%
  select(Libellé, company_category_translated) %>%
  distinct()

# Suppress unused data
learn_merged_uncoded <- learn_merged_uncoded %>%
  select(-Libellé)
rm(code_company_category)

################################ ECO - sect ###############################

# Import du fichier CSV
code_ECO_SECT <- read_csv("Data - source/project-10-files/code/code_ECO_SECT.csv")

learn_merged_uncoded <- learn_merged_uncoded

# Fusion des données
learn_merged_uncoded <- merge(learn_merged_uncoded, code_ECO_SECT, by.x = "ECO_SECT", by.y = "Code", all.x = TRUE, all.y = FALSE)
sum(is.na(learn_merged_uncoded$Libellé))  # Vérification des valeurs manquantes

# Traduction de "ECO_SECT"
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(ECO_SECT_translated = case_when(
    grepl("Agriculture, sylviculture et pêche", Libellé) ~ "Agriculture, forestry, and fishing",
    grepl("Industries extractives", Libellé) ~ "Mining and quarrying",
    grepl("Fabrication de denrées alimentaires", Libellé) ~ "Food, beverage, and tobacco manufacturing",
    grepl("Fabrication de textiles", Libellé) ~ "Textile, clothing, leather, and footwear manufacturing",
    grepl("Travail du bois", Libellé) ~ "Woodworking, paper industries, and printing",
    grepl("Cokéfaction et raffinage", Libellé) ~ "Coke and refining",
    grepl("Industrie chimique", Libellé) ~ "Chemical industry",
    grepl("Industrie pharmaceutique", Libellé) ~ "Pharmaceutical industry",
    grepl("Fabrication de produits en caoutchouc", Libellé) ~ "Rubber, plastic, and non-metallic mineral products manufacturing",
    grepl("Métallurgie", Libellé) ~ "Metallurgy and metal products manufacturing (excluding machinery and equipment)",
    grepl("Fabrication de produits informatiques", Libellé) ~ "Manufacture of computer, electronic, and optical products",
    grepl("Fabrication d'équipements électriques", Libellé) ~ "Electrical equipment manufacturing",
    grepl("Fabrication de machines", Libellé) ~ "Manufacture of machinery and equipment",
    grepl("Fabrication de matériels de transport", Libellé) ~ "Manufacture of transport equipment",
    grepl("Autres industries manufacturières", Libellé) ~ "Other manufacturing industries; repair and installation of machinery",
    grepl("Production et distribution d'électricité", Libellé) ~ "Electricity, gas, steam, and air conditioning supply",
    grepl("Production et distribution d'eau", Libellé) ~ "Water supply, sewerage, waste management, and remediation activities",
    grepl("Construction", Libellé) ~ "Construction",
    grepl("Commerce ; réparation d'automobiles", Libellé) ~ "Wholesale, retail trade, and repair of motor vehicles and motorcycles",
    grepl("Transports et entreposage", Libellé) ~ "Transportation and storage",
    grepl("Hébergement et restauration", Libellé) ~ "Accommodation and food service activities",
    grepl("Edition, audiovisuel et diffusion", Libellé) ~ "Publishing, broadcasting, and media",
    grepl("Télécommunications", Libellé) ~ "Telecommunications",
    grepl("Activités informatiques et services d'information", Libellé) ~ "Information technology and information services",
    grepl("Activités financières et d'assurance", Libellé) ~ "Financial and insurance activities",
    grepl("Activités immobilières", Libellé) ~ "Real estate activities",
    grepl("Activités juridiques, comptables", Libellé) ~ "Legal, accounting, management, architecture, engineering, and technical analysis activities",
    grepl("Recherche-développement scientifique", Libellé) ~ "Scientific research and development",
    grepl("Autres activités spécialisées", Libellé) ~ "Other specialized, scientific, and technical activities",
    grepl("Activités de services administratifs", Libellé) ~ "Administrative and support service activities",
    grepl("Administration publique", Libellé) ~ "Public administration",
    grepl("Enseignement", Libellé) ~ "Education",
    grepl("Activités pour la santé humaine", Libellé) ~ "Human health activities",
    grepl("Hébergement médico-social", Libellé) ~ "Residential care and social work activities",
    grepl("Arts, spectacles et activités récréatives", Libellé) ~ "Arts, entertainment, and recreation",
    grepl("Autres activités de services", Libellé) ~ "Other service activities",
    grepl("Activités des ménages en tant qu'employeurs", Libellé) ~ "Household employment activities",
    grepl("Activités extra-territoriales", Libellé) ~ "Extraterrestrial activities",
    TRUE ~ Libellé  # Garder le libellé original si aucune correspondance n'est trouvée
  ))

# Comparaison pour vérifier les traductions
comparison_table <- learn_merged_uncoded %>%
  select(Libellé, ECO_SECT_translated) %>%
  distinct()

# Suppression des colonnes inutiles
learn_merged_uncoded <- learn_merged_uncoded %>%
  select(-Libellé)
rm(code_ECO_SECT)
```

```{r Addition_of_the_translation_of_the_code_part_final, results = "hide"}

################################ Work Condition ###############################
# Translation
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(Work_condition_translated = case_when(
    Work_condition == "C" ~ "Full-time",
    Work_condition == "P" ~ "Part-time",
    Work_condition == "N" ~ "Not applicable",
    TRUE ~ Work_condition  # Conserver l'original si aucune correspondance
  ))

# Checking
comparison_table_work_condition <- learn_merged_uncoded %>%
  select(Work_condition, Work_condition_translated) %>%
  distinct()


################################ Job Category ###############################
# Traduction de "job_category"
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(job_category_translated = case_when(
    job_category == "O" ~ "Ordinary job",
    job_category == "A" ~ "Apprenticeship",
    job_category == "X" ~ "Other (subsidized job, trainee, unemployment benefit)",
    TRUE ~ job_category  # Conserver l'original si aucune correspondance
  ))

# Comparaison des colonnes originales et traduites pour "job_category"
comparison_table_job_category <- learn_merged_uncoded %>%
  select(job_category, job_category_translated) %>%
  distinct()

print(comparison_table_job_category)

################################ Employee Count ###############################
# Translation and decrypting
learn_merged_uncoded <- learn_merged_uncoded %>%
  mutate(employee_count_translated = case_when(
    employee_count == "tr_0" ~ "0 employee (employees present during the year but not on 31/12)",
    employee_count == "tr_1" ~ "1 to 9 employees",
    employee_count == "tr_2" ~ "10 to 19 employees",
    employee_count == "tr_3" ~ "20 to 49 employees",
    employee_count == "tr_4" ~ "50 to 99 employees",
    employee_count == "tr_5" ~ "100 to 249 employees",
    employee_count == "tr_6" ~ "250 employees and more",
    TRUE ~ employee_count  # Conserver l'original si aucune correspondance
  ))

# Check
comparison_table_employee_count <- learn_merged_uncoded %>%
  select(employee_count, employee_count_translated) %>%
  distinct()

################################ Sup. col. for checking ###############################
rm(comparison_table)
rm(comparison_table_employee_count)
rm(comparison_table_job_category)
rm(comparison_table_work_condition)

################################ Sup. col. original ###############################
columns_to_drop <- c(
  "ECO_SECT", "company_category", "last_emp_type", "emp_type", "LAST_JOB_42", "JOB_42",
  "Highest_degree", "Household_type", "act", "town_type")


learn_merged_uncoded_clean <- learn_merged_uncoded %>%
  select(-all_of(columns_to_drop))


```

The table below describe the percentage of missing value by variable in the learning set. The value of the main dataset has a 100% completion rate as we saw ealrier.

```{r}
na_percentage_per_column <- learn_merged %>%
  summarise(across(everything(), ~ sum(is.na(.)) / n() * 100)) %>%
  pivot_longer(everything(), names_to = "column_name", values_to = "na_percentage") %>%
  arrange((na_percentage))
na_percentage_per_column
```

Using the library "DateExplorer", we can visualize the result above.

```{r}
plot_missing(learn_merged) 
```

```{r}

learn_merged_with_Na <- learn_merged[, colSums(is.na(learn_merged)) > 1]

plot_missing(learn_merged_with_Na)
```

#### Missing values regarding employment variables

##### Analysis by activity status

Our first question was to understand whether they are pattern in the messing values. Among several way to deal with missing values Kumar G.R. (2024) quote the use of "Domain-specific knowledge". Similarly, we look at natural relationship between missing values and variable in the main dataset.

The table below count the percentage of missing values in variables linked to employment by activity status. Several missing cells seem logical corresponding to status where people does not work (housewives, retirees, unemployed and inactive people. "EMP_TYPE" have for example no missing values for active workers but missing values for other active status. The missing value in this case seems to correspond to the fact that "naturally" no data is expected for these subpopulations.

```{r}
na_percentage_by_act <- learn_merged_uncoded %>%
  group_by(act_translated) %>%
  summarise(
    Remuneration = round((sum(is.na(remuneration)) / n()) * 100, 0),
    ECO_SECT = round((sum(is.na(ECO_SECT)) / n()) * 100, 0),
    Emp_type = round((sum(is.na(emp_type)) / n()) * 100, 0),
    Job_category = round((sum(is.na(job_category)) / n()) * 100, 0),
    Job_dep = round((sum(is.na(Job_dep)) / n()) * 100, 0),
    Employee_count = round((sum(is.na(employee_count)) / n()) * 100, 0),
    Company_category = round((sum(is.na(company_category)) / n()) * 100, 0),
    Work_condition = round((sum(is.na(Work_condition)) / n()) * 100, 0),
    Working_hours = round((sum(is.na(Working_hours)) / n()) * 100, 0),
    TYPE_CONTRACT = round((sum(is.na(TYPE_CONTRACT)) / n()) * 100, 0)
  ) %>%
  arrange(desc(Remuneration))

kable(na_percentage_by_act, caption = "Percentage of Missing Values by Activity Status (Rounded to Nearest Whole Number)")


```

One question where to understand if there exist a pattern in the percent of missing values for active workers. A fith of the rows has missing values for several employment-related data for Active workers.

```{r}
# Keep only line corresponding to active worker."
active_workers_data <- learn_merged_uncoded %>%
  filter(act == "ACT1.1")

# Calcul du pourcentage de valeurs manquantes et non manquantes pour chaque variable
active_workers_na_percentage <- active_workers_data %>%
  summarise(
    Remuneration_sep_missing = round(sum(is.na(remuneration)) / n() * 100, 0),
    Remuneration_sep_not_missing = round(sum(!is.na(remuneration)) / n() * 100, 0),
    ECO_SECT_sep_missing = round(sum(is.na(ECO_SECT)) / n() * 100, 0),
    ECO_SECT_sep_not_missing = round(sum(!is.na(ECO_SECT)) / n() * 100, 0),
    Emp_type_sep_missing = round(sum(is.na(emp_type)) / n() * 100, 0),
    Emp_type_sep_not_missing = round(sum(!is.na(emp_type)) / n() * 100, 0),
    Job_category_sep_missing = round(sum(is.na(job_category)) / n() * 100, 0),
    Job_category_sep_not_missing = round(sum(!is.na(job_category)) / n() * 100, 0),
    Job_dep_sep_missing = round(sum(is.na(Job_dep)) / n() * 100, 0),
    Job_dep_sep_not_missing = round(sum(!is.na(Job_dep)) / n() * 100, 0),
    Employee_count_sep_missing = round(sum(is.na(employee_count)) / n() * 100, 0),
    Employee_count_sep_not_missing = round(sum(!is.na(employee_count)) / n() * 100, 0),
    Company_category_sep_missing = round(sum(is.na(company_category)) / n() * 100, 0),
    Company_category_sep_not_missing = round(sum(!is.na(company_category)) / n() * 100, 0),
    Work_condition_sep_missing = round(sum(is.na(Work_condition)) / n() * 100, 0),
    Work_condition_sep_not_missing = round(sum(!is.na(Work_condition)) / n() * 100, 0),
    Working_hours_sep_missing = round(sum(is.na(Working_hours)) / n() * 100, 0),
    Working_hours_sep_not_missing = round(sum(!is.na(Working_hours)) / n() * 100, 0),
    TYPE_CONTRACT_sep_missing = round(sum(is.na(TYPE_CONTRACT)) / n() * 100, 0),
    TYPE_CONTRACT_sep_not_missing = round(sum(!is.na(TYPE_CONTRACT)) / n() * 100, 0)
  )

# Transposing
active_workers_na_percentage <- active_workers_na_percentage %>%
  pivot_longer(
    everything(),
    names_to = c("Variable", "Status"),
    names_sep = "_sep_"
  ) %>%
  pivot_wider(
    names_from = "Status",
    values_from = "value"
  )%>%
  rename(
    `Missing values` = missing,
    `Non-missing value` = not_missing
  )


kable(active_workers_na_percentage, caption = "Percentage of missing Values for active workers")


```

Looking at a more granular scale, one can observe that several subcategories of active workers has high number of missing values. It is notably the case of self-employed person and at a smaller scale of subsidized jobs, paid trainess and apprenticeship.

```{r}
#Reminder  acvite_worker_data is computed through active_workers_data learn_merged_uncoded %>% filter(act == "ACT1.1")



aw_na_by_emptype_percent <- active_workers_data %>%
  group_by(emp_type_translated) %>%
  summarise(
    Remuneration = round(sum(is.na(remuneration)) / n() * 100, 0),
    ECO_SECT = round(sum(is.na(ECO_SECT)) / n() * 100, 0),
    Job_category = round(sum(is.na(job_category)) / n() * 100, 0),
    Job_dep = round(sum(is.na(Job_dep)) / n() * 100, 0),
    Employee_count = round(sum(is.na(employee_count)) / n() * 100, 0),
    Company_category = round(sum(is.na(company_category)) / n() * 100, 0),
    Work_condition = round(sum(is.na(Work_condition)) / n() * 100, 0),
    Working_hours = round(sum(is.na(Working_hours)) / n() * 100, 0),
    TYPE_CONTRACT = round(sum(is.na(TYPE_CONTRACT)) / n() * 100, 0)
  ) %>% 
  arrange(desc(Remuneration))

kable(aw_na_by_emptype_percent, caption = "Percentage of Missing Values by Employment type")
```

We try to go further in the analysis by identifying if, for these subpopulation with large percentage of NA, the use of variable "JOB_42" help us found some logical patterns.

This time also, some subcategory seem to have only missing values.

```{r}
#Reminder  acvite_worker_data is computed through active_workers_data learn_merged_uncoded %>% filter(act == "ACT1.1")

active_workers_data_filtered <- active_workers_data %>%
  filter(emp_type %in% c("EMP1.1", "EMP1.3", "EMP1.4"))

aw_na_by_job_percent <- active_workers_data_filtered %>%
  group_by(JOB_42_translated) %>%
  summarise(
    Remuneration = round(sum(is.na(remuneration)) / n() * 100, 0),
    ECO_SECT = round(sum(is.na(ECO_SECT)) / n() * 100, 0),
    Job_category = round(sum(is.na(job_category)) / n() * 100, 0),
    Job_dep = round(sum(is.na(Job_dep)) / n() * 100, 0),
    Employee_count = round(sum(is.na(employee_count)) / n() * 100, 0),
    Company_category = round(sum(is.na(company_category)) / n() * 100, 0),
    Work_condition = round(sum(is.na(Work_condition)) / n() * 100, 0),
    Working_hours = round(sum(is.na(Working_hours)) / n() * 100, 0),
    TYPE_CONTRACT = round(sum(is.na(TYPE_CONTRACT)) / n() * 100, 0)
  ) %>% 
  arrange(desc(Remuneration))

kable(aw_na_by_job_percent, caption = "Percentage of Missing Values by Job 42 Translated for ACT1.1")
```

However, at their individual scale, the number of individuals that they represent is quite low.

```{r}
aw_na_by_job_n <- active_workers_data_filtered %>%
  group_by(JOB_42_translated) %>%
  summarise(
    Remuneration = round(sum(is.na(remuneration)), 0),
    ECO_SECT = round(sum(is.na(ECO_SECT)), 0),
    Emp_type = round(sum(is.na(emp_type)), 0),
    Job_category = round(sum(is.na(job_category)), 0),
    Job_dep = round(sum(is.na(Job_dep)), 0),
    Employee_count = round(sum(is.na(employee_count)), 0),
    Company_category = round(sum(is.na(company_category)), 0),
    Work_condition = round(sum(is.na(Work_condition)), 0),
    Working_hours = round(sum(is.na(Working_hours)), 0),
    TYPE_CONTRACT = round(sum(is.na(TYPE_CONTRACT)), 0)
  )

kable(aw_na_by_job_n, caption = "Number of Missing Values by Job 42 Translated for ACT1.1")
```

#### Missing values regarding retirement variables

##### Analysis by activity status

As a reminder, the variables with the bigger number of missing values are often linked with retirement status. Our hypothesis were that a large chunk of the missing values in the column linked to retired (column starting by "LAST" or containing a name of the lexical field of "retirement") correspond to rows with non-retired individual.

```{r}

learn_merged_with_Na <- learn_merged[, colSums(is.na(learn_merged)) > 1]

plot_missing(learn_merged_with_Na)
```

To check this hypothesis, we look at the percentage of missing values by activity status.

```{r}
# Total number of NA per column
total_na_per_column <- learn_merged_uncoded %>%
  summarise(
    Total_LAST_JOB_42 = sum(is.na(LAST_JOB_42)),
    Total_last_emp_type = sum(is.na(last_emp_type)),
    Total_retirement_age = sum(is.na(retirement_age)),
    Total_Retirement_pay = sum(is.na(Retirement_pay))
  )

# Our final table
na_percentage_by_act_ret <- learn_merged_uncoded %>%
  group_by(act_translated) %>%
  summarise(
    LAST_JOB_42 = round(sum(is.na(LAST_JOB_42)) / total_na_per_column$Total_LAST_JOB_42 * 100, 2),
    last_emp_type = round(sum(is.na(last_emp_type)) / total_na_per_column$Total_last_emp_type * 100, 2),
    retirement_age = round(sum(is.na(retirement_age)) / total_na_per_column$Total_retirement_age * 100, 2),
    Retirement_pay = round(sum(is.na(Retirement_pay)) / total_na_per_column$Total_Retirement_pay * 100, 2)
  ) %>%
  arrange(desc(LAST_JOB_42))


kable(na_percentage_by_act_ret, caption = "Percentage of Missing Values by Activity Status (Percentage relative to the column)")


```

By precaution, we wanted to check whether there were retirement data for active workers. However, the sanity check did not find any.

```{r}
# Same work for non missing values

# Total number of non-NA per column
total_non_na_per_column <- learn_merged_uncoded %>%
  summarise(
    Total_LAST_JOB_42 = sum(!is.na(LAST_JOB_42)),
    Total_last_emp_type = sum(!is.na(last_emp_type)),
    Total_retirement_age = sum(!is.na(retirement_age)),
    Total_Retirement_pay = sum(!is.na(Retirement_pay))
  )

# Our final table with percentages of non-missing values
non_na_percentage_by_act_ret <- learn_merged_uncoded %>%
  group_by(act_translated) %>%
  summarise(
    LAST_JOB_42 = round(sum(!is.na(LAST_JOB_42)) / total_non_na_per_column$Total_LAST_JOB_42 * 100, 2),
    last_emp_type = round(sum(!is.na(last_emp_type)) / total_non_na_per_column$Total_last_emp_type * 100, 2),
    retirement_age = round(sum(!is.na(retirement_age)) / total_non_na_per_column$Total_retirement_age * 100, 2),
    Retirement_pay = round(sum(!is.na(Retirement_pay)) / total_non_na_per_column$Total_Retirement_pay * 100, 2)
  ) %>%
  arrange(desc(LAST_JOB_42))

# Display the table with kable
kable(non_na_percentage_by_act_ret, caption = "Percentage of Non-Missing Values by Activity Status (Percentage relative to the column)")

```

Only 2% of the retired individual has missing values for retirement-related data. One variable is an exception : the retirement pay.

```{r}
#
na_percentage_by_act_value <- learn_merged_uncoded %>%
  group_by(act_translated) %>%
  summarise(
    LAST_JOB_42 = round(sum(is.na(LAST_JOB_42)) / n() * 100, 2),
    last_emp_type = round(sum(is.na(last_emp_type)) / n() * 100, 2),
    retirement_age = round(sum(is.na(retirement_age)) / n() * 100, 2),
    Retirement_pay = round(sum(is.na(Retirement_pay)) / n() * 100, 2)
  ) %>%
  arrange(desc(LAST_JOB_42))  


kable(na_percentage_by_act_value, caption = "Percentage of Missing Values  for Each Activity Status")

```

The minimum value of retirement pay for retired person is non null. An hypothesis could be that the null value corresponds to retired person without retirement pay. However, regarding the french welfare system, this hypothesis seems to us to have a low probability to be true.

```{r}
#Dataset with only retired people 
# + : adition of a factorial value for retirement pay for the following graph
retirees_data <- learn_merged_uncoded %>%
  filter(act_translated == "Retirees or early retirees")

#Stats on retirement pay
summary_stats <- learn_merged_uncoded %>%
  filter(act_translated == "Retirees or early retirees") %>%
  summarise(
    min = min(Retirement_pay, na.rm = TRUE),
    max = max(Retirement_pay, na.rm = TRUE),
    mean = mean(Retirement_pay, na.rm = TRUE),
    median = median(Retirement_pay, na.rm = TRUE),
    sd = sd(Retirement_pay, na.rm = TRUE),
    na_count = sum(is.na(Retirement_pay))
  )

summary_stats

```

#### Missing values regarding sport-related variable

The last part of the data exploration concern missing values of the "Club Membership Dataset". There are datas with the highest percentage of missing values and a prevalence so important of NA that the question was wheter to use them or not. Similarly to the last part, the question was if this missing values was explained by structural relationships.

The percent of person with non missing values are lower in students. A plausible hypothesis is that the number of missing values is (partially) driven by the number of person who does not practice a sport. However, it is unkown if other factor explain the distribution of the variable.

```{r}
# Total number of non-NA per column
total_na_per_column_sport <- learn_merged_uncoded %>%
  summarise(
    Total_sport = sum(is.na(sports)))

# Our final table with percentages of non-missing values
na_percentage_by_act_sport <- learn_merged_uncoded %>%
  group_by(act_translated) %>%
  summarise(
    sports = round(sum(is.na(sports)) / n() * 100, 2)) %>%
  arrange(desc(sports))

# Display the table with kable
kable(na_percentage_by_act_sport, caption = "Percentage of Missing Values by Activity Status (Percentage relative to the population in row)")

```

## Used solutions

Basing our reflections on the descriptive statistics of the next sections, several decisions were maded:

1.  Not using variable in the sport dataset : because of its high number of missing values and non clear pattern, the variable was put aside.

```{r}
learn_merged <- learn_merged %>%
  select(-sports)
```

1.  For work-related variable :

    -   Fill the missing values with "Not applicable" for all non-numerical variables and"-1"
        -   for numerical values for the active status that are not either retiree or active worker
        -   and, for active workers wo are self employed

    ```{r}
    # List of work-related variables
    work_related_var <- c("remuneration", "ECO_SECT", "emp_type", "job_category",
                          "Job_dep", "employee_count", "company_category",
                          "Work_condition", "Working_hours", "TYPE_CONTRACT")

    # Transformation using a loop for active status
    for (var in work_related_var) {
      learn_merged[[var]] <- ifelse(
        is.na(learn_merged[[var]]) & !(learn_merged$act %in% c("ACT2.1", "ACT1.1")) & is.numeric(learn_merged[[var]]), 
        -1,
        ifelse(
          is.na(learn_merged[[var]]) & !(learn_merged$act %in% c("ACT2.1", "ACT1.1")) & !is.numeric(learn_merged[[var]]), 
          "Not applicable", 
          learn_merged[[var]]))}

    # Transformation using a loop for self employed
    for (var in work_related_var) {
      learn_merged[[var]] <- ifelse(
        is.na(learn_merged[[var]]) & (learn_merged$emp_type %in% c("EMP2.1", "EMP2.2", "EMP2.3")) & is.numeric(learn_merged[[var]]), 
        -1,
        ifelse(
          is.na(learn_merged[[var]]) & (learn_merged$emp_type %in% c("EMP2.1", "EMP2.2", "EMP2.3")) & !is.numeric(learn_merged[[var]]), 
          "Not applicable", 
          learn_merged[[var]]))}

    learn_merged %>% group_by(act) %>% 
      summarise(across(all_of(work_related_var), ~ sum(is.na(.)))) %>%
      knitr::kable(caption = "Number of Missing Values after Transformation")


    ```

    -   And to impute missing values for the other

2.  For retirement related-variable :

    -   Fill the missing values for non-retired people with "Not applicable" (for non numeric value) or "-1" (for numerical one)

    ```{r}
    # (1) Define the list of retirement-related variables
    retirement_related_var <- c("LAST_JOB_42", "last_emp_type", "retirement_age", "Retirement_pay")

    # (2) Apply the transformation only for missing values when act is NOT "ACT2.1"
    for (var in retirement_related_var) {
      learn_merged[[var]] <- ifelse(
        is.na(learn_merged[[var]]) & learn_merged$act != "ACT2.1" & is.numeric(learn_merged[[var]]),
        -1,
        ifelse(
          is.na(learn_merged[[var]]) & learn_merged$act != "ACT2.1" & !is.numeric(learn_merged[[var]]),
          "Not applicable",
          learn_merged[[var]]))}

    # (3) Visualize the percentage of missing values after transformation

    learn_merged %>% group_by(act) %>% 
      summarise(across(all_of(retirement_related_var), ~ sum(is.na(.)))) %>%
      knitr::kable(caption = "Number of Missing Values after Transformation")
    ```

    -   For retired people :impute the missing values

```{r}

columns_to_impute <- names(learn_merged)[
  colSums(is.na(learn_merged)) > 0]


#####################   Reminder : Stats before imputation    #####################

before_imputation_summary <- learn_merged %>%
  summarise(across(all_of(columns_to_impute), ~ round(sum(is.na(.)) / n() * 100, 2)))


before_imputation_summary %>%
  t() %>%  
  as.data.frame() %>%
  kable(caption = "Percentage of Missing Values Before Imputation for Each Variable")





```

**Test with recipes**

```{r}


### Test with recipe

lasagna <- recipe(target ~ ., data = learn_merged)
knn_step <- lasagnaa %>% step_impute_knn(all(predictors()))

knn_step




####################   Post - Imputation Summary  ##############################

# Display a summary table of missing values after imputation
after_imputation_summary %>%
  t() %>%  # Transpose to show variables as rows
  as.data.frame() %>%
  kable(caption = "Percentage of Missing Values After Imputation for Each Variable")

```

**Test with recipes 2**

```{r}

my_recipe <- recipe(target ~ ., data = learn_merged) %>%
  step_impute_bag(all_numeric_predictors()) %>%
  step_impute_bag(all_nominal_predictors())


prep_it <- prep(my_recipe, training = learn_merged)


learn_imputed <- bake(prep_it, new_data = learn_merged)

# Checking the result
after_imputation_summary <- learn_imputed %>%
  summarise(across(all_of(columns_to_impute), ~ round(sum(is.na(.)) / n() * 100, 2)))

```

**Test with misforest**

Misforest is described as a nonparametric solution wihich is fitted to impute missing values with mixed-type data

```{r}

#############################       Imputation        ##############################
# **Perform Random Forest-based imputation with missForest**
imputed_test <- missForest(learn_merged, maxiter = 10, ntree = 100)

####################   Post - Imputation Summary  ##############################
after_imputation_summary <- learn_merged %>%
  summarise(across(all_of(columns_to_impute), ~ round(sum(is.na(.)) / n() * 100, 2)))
# Display a summary table of missing values after imputation
after_imputation_summary %>%
  t() %>%  # Transpose to show variables as rows
  as.data.frame() %>%
  kable(caption = "Percentage of Missing Values After Imputation for Each Variable")
```

```         
```

# Machine learning models

One hot encoding

```{r}
# Pre-processing : Hot encoding
```

## Decision Tree

```{r}
##  Creation of the tree

my_tree <- decision_tree(
  cost_complexity = tune(),
  min_n = tune(),
  tree_depth = tune()
) %>%
  set_mode("classification") %>%
  set_engine("rpart")

tree_workflow <- workflow() %>%
  add_model(my_tree) %>%
  add_recipe(cookbook)



my_grid <- expand.grid(
  cost_complexity =  c(0, 0.1, 0.01, 0.001, 0.0001), 
  min_n =  c(2L, 10L, 50L, 100L, 150L, 200L),                
  tree_depth = c(2L,4L, 5L, 7L, 10L, 15L))

## Re-sampling
set.seed(12)
compound_v <- vfold_cv(learn_merged, v = 5, strata = target)

## Using tune_grid on the tree


X <- setdiff(names(learn_merged), c("target"))

model_formula <- as.formula(paste("target ~", paste(X, collapse = " + ")))

my_tuned_tree <- tree_workflow %>% 
  tune_grid(model_formula,
            resamples = compound_v,
            grid = my_grid,
            control = control_grid(save_workflow = TRUE))
```

Graph

```{r}
tuning_results <- collect_metrics(my_tuned_tree)

my_results <- tuning_results %>%
  filter(.metric == "accuracy")

min_n_graph_a <- ggplot(my_results, aes(x = min_n, y = mean, color = as.factor(tree_depth))) +
  geom_line() +
  geom_point() +
  facet_wrap(~ cost_complexity, scales = "free_y") +
  theme_minimal() +
  labs(
    title = "Accuracy by minimum number of observations per node and tree depth faceted by cost complexity",
     y = "Accuracy",
     color = "Tree Depth")

print(min_n_graph_a)
```

Our final tree using accuracy as key metric has the following parameters :

```{r}
my_best_parameters <- my_tuned_tree %>%    select_best(metric = "accuracy")  kable(my_best_parameters, caption = "Best Parameters for the Decision Tree Model")
```

```{r}
my_final_tree_workflow <-  finalize_workflow(tree_workflow ,my_best_parameters)

final_fit <- my_final_tree_workflow %>% last_fit(model_formula, data = learn_merged)
```

Confusion Matrices

## Random Forest

```{r}
#random forest model

amazonia <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune()) %>%
  set_mode("classification") %>%
  set_engine("ranger")

forest_workflow <- workflow() %>%
  add_model(amazonia) %>%
  add_recipe(cookbook)

# Grid
my_grid_rf <- expand.grid(
  mtry = c(1L, 3L, 5L, 7L, 9L, 12L,15L), 
  min_n = c(2L, 10L, 50L, 100L),
  trees = c(100L, 200L,300L))

# Cv fold
homelander <- vfold_cv(learn_merged, v = 5, strata = target)

amazonia_tuned <- tune_grid(
  amazonia,
  preprocessor = model_formula, 
  resamples = homelander,
  grid = my_grid_rf,
  metrics = metric_set(accuracy, roc_auc))

# Best parameters
best_rf_params <- amazonia_tuned %>%
  select_best(metric = "accuracy")
```

characteristics of the random forest

```{r}
print(best_rf_params)
kable(best_rf_params, caption = "Parameters of the random forest model")
```

```{r}
# Final model
final_amazonia_workflow <- finalize_workflow(best_rf_params)

amazonia_fit <- finalize_workflow %>%
  fit(final_amazonia_workflow, data = learn_merged)
```

Concusion matrices

```{r}
# Predictions on training set
train_predictions_rf <- amazonia_fit %>%
  predict(new_data = learn_merged) %>%
  bind_cols(learn_merged %>% select(target))

train_conf_matrix_rf <- train_predictions_rf %>%
  conf_mat(truth = target, estimate = .pred_class)

# Predictions on test set
test_predictions_rf <- amazonia_fit %>%
  predict(new_data = test_data_rf) %>%
  bind_cols(test_data_rf %>% select(target))

test_conf_matrix_rf <- test_predictions_rf %>%
  conf_mat(truth = target, estimate = .pred_class)

```

```{r}
# Heatmap for training set
train_matrix_rf <- autoplot(train_conf_matrix_rf, type = "heatmap") +
  scale_fill_viridis_c(option = "plasma") +
  labs(title = "Panel A: Training Set (Random Forest)") +
  theme(plot.title = element_text(hjust = 0.5))

# Heatmap for test set
test_matrix_rf <- autoplot(test_conf_matrix_rf, type = "heatmap") +
  scale_fill_viridis_c(option = "plasma") +
  labs(title = "Panel B: Test Set (Random Forest)") +
  theme(plot.title = element_text(hjust = 0.5))

# Combine the two heatmaps
fusion_rf <- (train_matrix_rf | test_matrix_rf) +
  plot_annotation(
    title = "Figure 5: Confusion Matrices for Training and Test Sets (Random Forest)",
    theme = theme(plot.title = element_text(hjust = 0.5)))

# Display the combined heatmap
print(fusion_rf)

```

```{r}
train_metrics <- train_predictions_rf %>%
  metrics(truth = target, estimate = .pred_class)

# Print the metrics as a formatted table
train_metrics %>%
  kable(
    caption = "Key Metrics for the Training Set (Random Forest)")
```

## **Gradient Boosting Machines**

# References

<https://medium.com/>@ajayverma23/data-imputation-a-comprehensive-guide-to-handling-missing-values-b5c7d11c3488
